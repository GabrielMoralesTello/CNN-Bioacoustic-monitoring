{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.models import model_from_json\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications import ResNet50\n",
    "import keras.models as models\n",
    "import keras.layers as layers\n",
    "import tensorflow as tf\n",
    "import _pickle as pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "import os\n",
    "import json\n",
    "import datetime\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specify the model name and training data paths below\n",
    "\n",
    "Separate directories for positive and negative examples of each class should be specified in train_dir_tp, and train_dir_fp, respectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "model_file_name = 'ResNet50_test' # name of trained model file\n",
    "model_path = '/home/gabsoni/Documentos/ENTORNOS/exp1/arbimon2-cnn/model' # path to directory where model will be stored\n",
    "\n",
    "train_dir_tp = '/home/gabsoni/Documentos/ENTORNOS/exp1/arbimon2-cnn/train_tp' # directory with examples of true-positive spectrograms of each class\n",
    "train_dir_fp = '/home/gabsoni/Documentos/ENTORNOS/exp1/arbimon2-cnn/train_fp' # directory with examples of false-positive spectrograms of each class\n",
    "\n",
    "num_classes = 1\n",
    "input_shape = [224, 224, 3]\n",
    "batch_size = 32\n",
    "epochs = 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run remaining cells to begin training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "188\n",
      "188\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/home/gabsoni/Documentos/ENTORNOS/exp1/arbimon...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/home/gabsoni/Documentos/ENTORNOS/exp1/arbimon...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/home/gabsoni/Documentos/ENTORNOS/exp1/arbimon...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/home/gabsoni/Documentos/ENTORNOS/exp1/arbimon...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/home/gabsoni/Documentos/ENTORNOS/exp1/arbimon...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            filename    0\n",
       "0  /home/gabsoni/Documentos/ENTORNOS/exp1/arbimon...  1.0\n",
       "1  /home/gabsoni/Documentos/ENTORNOS/exp1/arbimon...  1.0\n",
       "2  /home/gabsoni/Documentos/ENTORNOS/exp1/arbimon...  1.0\n",
       "3  /home/gabsoni/Documentos/ENTORNOS/exp1/arbimon...  1.0\n",
       "4  /home/gabsoni/Documentos/ENTORNOS/exp1/arbimon...  1.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = []\n",
    "target = []\n",
    "class_dict = dict()\n",
    "validation_split = 0.1\n",
    "\n",
    "for c, i in enumerate(sorted(os.listdir(train_dir_tp))):\n",
    "    class_dict[c] = i\n",
    "    for j in os.listdir(train_dir_tp+'/'+i):\n",
    "        files.append(train_dir_tp+'/'+i+'/'+j)\n",
    "        tmp = np.empty(num_classes)\n",
    "        tmp[:] = np.nan\n",
    "        tmp[c] = int(1)\n",
    "        target.append(tmp)\n",
    "        \n",
    "for c, i in enumerate(sorted(os.listdir(train_dir_fp))):\n",
    "    class_dict[c] = i\n",
    "    for j in os.listdir(train_dir_fp+'/'+i):\n",
    "        files.append(train_dir_fp+'/'+i+'/'+j)\n",
    "        tmp = np.empty(num_classes)\n",
    "        tmp[:] = np.nan\n",
    "        tmp[c] = int(0)\n",
    "        target.append(tmp)\n",
    "        \n",
    "df_train = pd.concat([pd.DataFrame({'filename':files}),pd.DataFrame(np.asarray(target))],axis=1)\n",
    "\n",
    "print(len(df_train))\n",
    "validation_indices = np.random.choice(range(len(df_train)), size=int(len(df_train)*validation_split), replace=False)\n",
    "df_validation = df_train.iloc[validation_indices]\n",
    "df_train.drop(df_train.index[validation_indices], inplace=True)\n",
    "print(len(df_train)+len(df_validation))\n",
    "df_validation.reset_index(drop=True, inplace=True)\n",
    "df_train.reset_index(drop=True, inplace=True)\n",
    "df_train.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 170 validated image filenames.\n",
      "Found 18 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1/255.0)\n",
    "\n",
    "validation_datagen = ImageDataGenerator(rescale=1/255.0)\n",
    "\n",
    "train_generator = train_datagen.flow_from_dataframe(df_train,\n",
    "                                                    y_col=range(num_classes),\n",
    "                                                    directory=None,\n",
    "                                                    target_size=input_shape[:2],\n",
    "                                                    batch_size=batch_size,\n",
    "                                                    class_mode='raw')\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_dataframe(df_validation,\n",
    "                                                        y_col=range(num_classes),\n",
    "                                                        directory=None,\n",
    "                                                        target_size=input_shape[:2],\n",
    "                                                        batch_size=batch_size,\n",
    "                                                        class_mode='raw')\n",
    "\n",
    "def generator_wrapper(generator):\n",
    "    for batch_x, batch_y in generator:\n",
    "        yield (batch_x, np.row_stack(batch_y))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def masked_loss(y_true, y_pred):\n",
    "    return K.mean(K.mean(K.binary_crossentropy(tf.where(tf.math.is_nan(y_true), tf.zeros_like(y_true), y_true),\n",
    "                                        tf.multiply(y_pred, tf.cast(tf.logical_not(tf.math.is_nan(y_true)), tf.float32))), axis=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "resnet50 (Functional)        (None, 7, 7, 2048)        23587712  \n",
      "_________________________________________________________________\n",
      "average_pooling2d_1 (Average (None, 1, 1, 2048)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 512)               1049088   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 24,637,313\n",
      "Trainable params: 24,584,193\n",
      "Non-trainable params: 53,120\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Load the ResNet50 model\n",
    "ResNet50_conv = ResNet50(weights='imagenet', \n",
    "                         include_top=False, \n",
    "                         input_shape=input_shape)\n",
    "\n",
    "for layer in ResNet50_conv.layers:\n",
    "    layer.trainable = True\n",
    "\n",
    "# Create the model\n",
    "model = models.Sequential()\n",
    "# Add the convolutional base model\n",
    "model.add(ResNet50_conv)\n",
    "\n",
    "model.add(layers.AveragePooling2D((7, 7)))\n",
    "\n",
    "# Add new layers\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(512, activation='relu'))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(num_classes, activation='sigmoid'))\n",
    "\n",
    " # Compile the model\n",
    "optimizer = keras.optimizers.Adam(lr=0.0001, decay=1e-7)\n",
    "model.compile(loss=masked_loss, optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model architecture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gabsoni/miniconda3/envs/exp1/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 40s 6s/step - loss: 0.9403 - accuracy: 0.3598 - val_loss: 0.6365 - val_accuracy: 0.6667\n",
      "Saving model...\n"
     ]
    }
   ],
   "source": [
    "model_json = model.to_json()\n",
    "with open(model_path+'/'+model_file_name+'.json', \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "with open(model_path+'/'+model_file_name+'_classes.json', 'w') as f:\n",
    "    json.dump(class_dict, f)\n",
    "print('Saved model architecture')\n",
    "    \n",
    "model_history = model.fit_generator(train_generator,\n",
    "                                steps_per_epoch = len(train_generator),\n",
    "                                epochs = epochs,\n",
    "                                validation_data = validation_generator,\n",
    "                                validation_steps = len(validation_generator),\n",
    "                                verbose = 1)\n",
    "print('Saving model...')\n",
    "model.save_weights(model_path+'/'+model_file_name+'.h5')       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "exp1",
   "language": "python",
   "name": "exp1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
